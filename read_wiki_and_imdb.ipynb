{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install --ignore-installed --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim import corpora, utils\n",
    "from gensim.models.wrappers.dtmmodel import DtmModel\n",
    "from collections import defaultdict, Counter\n",
    "import sklearn.metrics\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import nltk\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in wikipedia and imdb data set from .pickle file:\n",
    "data = pd.read_pickle('clean_complete_ngram.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>reviews</th>\n",
       "      <th>content</th>\n",
       "      <th>reviews_tri</th>\n",
       "      <th>contents_tri</th>\n",
       "      <th>reviews_bi</th>\n",
       "      <th>contents_bi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dead Awake</td>\n",
       "      <td>2016</td>\n",
       "      <td>investig death twin sister sleep social worker...</td>\n",
       "      <td>movi new havent seen name 3 4 last yeari famil...</td>\n",
       "      <td>dead awak 2016 american supernatur psycholog h...</td>\n",
       "      <td>{('good', 'horror', 'film'): 1, ('good', 'job'...</td>\n",
       "      <td>{('refer', 'extern', 'link'): 1, ('extern', 'l...</td>\n",
       "      <td>{('dream', 'movi'): 1, ('right', 'right'): 1, ...</td>\n",
       "      <td>{('world', 'premier'): 1, ('psycholog', 'horro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A Good American</td>\n",
       "      <td>2015</td>\n",
       "      <td>documentari reveal truth nsa cryptologist inno...</td>\n",
       "      <td>documentari show situat idea know bit heard re...</td>\n",
       "      <td>good american 2015 austrian documentari film c...</td>\n",
       "      <td>{}</td>\n",
       "      <td>{('new', 'york', 'time'): 1, ('refer', 'extern...</td>\n",
       "      <td>{('make', 'sens'): 1, ('compel', 'film'): 1, (...</td>\n",
       "      <td>{('produc', 'direct'): 1, ('score', 'film'): 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hard Tide</td>\n",
       "      <td>2015</td>\n",
       "      <td>drug dealer who emul father success crimin car...</td>\n",
       "      <td>watch rot last night tempt dont bother script ...</td>\n",
       "      <td>hard tide 2015 british crime drama written dir...</td>\n",
       "      <td>{('doesnt', 'take', 'long'): 1, ('nine', 'year...</td>\n",
       "      <td>{('gave', 'film', 'posit'): 1, ('recept', 'rot...</td>\n",
       "      <td>{('want', 'good'): 1, ('watch', 'film'): 1, ('...</td>\n",
       "      <td>{('total', 'film'): 1, ('hard', 'time'): 1, ('...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Carrie Pilby</td>\n",
       "      <td>2016</td>\n",
       "      <td>social awkward 19yearold geniu make big plan s...</td>\n",
       "      <td>excit see film toronto filmfest last week enjo...</td>\n",
       "      <td>carri pilbi 2016 american comedi film direct s...</td>\n",
       "      <td>{('excit', 'see', 'film'): 1, ('toronto', 'fil...</td>\n",
       "      <td>{('acquir', 'distribut', 'right'): 1, ('right'...</td>\n",
       "      <td>{('good', 'role'): 1, ('watch', 'film'): 1, ('...</td>\n",
       "      <td>{('film', 'star'): 1, ('refer', 'extern'): 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A Dark Song</td>\n",
       "      <td>2016</td>\n",
       "      <td>griev death son woman hire occult expert lead ...</td>\n",
       "      <td>writer felt job review mere whine prattl happe...</td>\n",
       "      <td>dark song 2016 irish independ horror film writ...</td>\n",
       "      <td>{('good', 'horror', 'film'): 1, ('act', 'prett...</td>\n",
       "      <td>{('film', 'festiv', 'releas'): 1, ('film', 're...</td>\n",
       "      <td>{('vast', 'major'): 1, ('fantast', 'film'): 1,...</td>\n",
       "      <td>{('end', 'definit'): 1, ('festiv', 'releas'): ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              title  year                                           synopsis  \\\n",
       "0        Dead Awake  2016  investig death twin sister sleep social worker...   \n",
       "10  A Good American  2015  documentari reveal truth nsa cryptologist inno...   \n",
       "11        Hard Tide  2015  drug dealer who emul father success crimin car...   \n",
       "13     Carrie Pilby  2016  social awkward 19yearold geniu make big plan s...   \n",
       "14      A Dark Song  2016  griev death son woman hire occult expert lead ...   \n",
       "\n",
       "                                              reviews  \\\n",
       "0   movi new havent seen name 3 4 last yeari famil...   \n",
       "10  documentari show situat idea know bit heard re...   \n",
       "11  watch rot last night tempt dont bother script ...   \n",
       "13  excit see film toronto filmfest last week enjo...   \n",
       "14  writer felt job review mere whine prattl happe...   \n",
       "\n",
       "                                              content  \\\n",
       "0   dead awak 2016 american supernatur psycholog h...   \n",
       "10  good american 2015 austrian documentari film c...   \n",
       "11  hard tide 2015 british crime drama written dir...   \n",
       "13  carri pilbi 2016 american comedi film direct s...   \n",
       "14  dark song 2016 irish independ horror film writ...   \n",
       "\n",
       "                                          reviews_tri  \\\n",
       "0   {('good', 'horror', 'film'): 1, ('good', 'job'...   \n",
       "10                                                 {}   \n",
       "11  {('doesnt', 'take', 'long'): 1, ('nine', 'year...   \n",
       "13  {('excit', 'see', 'film'): 1, ('toronto', 'fil...   \n",
       "14  {('good', 'horror', 'film'): 1, ('act', 'prett...   \n",
       "\n",
       "                                         contents_tri  \\\n",
       "0   {('refer', 'extern', 'link'): 1, ('extern', 'l...   \n",
       "10  {('new', 'york', 'time'): 1, ('refer', 'extern...   \n",
       "11  {('gave', 'film', 'posit'): 1, ('recept', 'rot...   \n",
       "13  {('acquir', 'distribut', 'right'): 1, ('right'...   \n",
       "14  {('film', 'festiv', 'releas'): 1, ('film', 're...   \n",
       "\n",
       "                                           reviews_bi  \\\n",
       "0   {('dream', 'movi'): 1, ('right', 'right'): 1, ...   \n",
       "10  {('make', 'sens'): 1, ('compel', 'film'): 1, (...   \n",
       "11  {('want', 'good'): 1, ('watch', 'film'): 1, ('...   \n",
       "13  {('good', 'role'): 1, ('watch', 'film'): 1, ('...   \n",
       "14  {('vast', 'major'): 1, ('fantast', 'film'): 1,...   \n",
       "\n",
       "                                          contents_bi  \n",
       "0   {('world', 'premier'): 1, ('psycholog', 'horro...  \n",
       "10  {('produc', 'direct'): 1, ('score', 'film'): 1...  \n",
       "11  {('total', 'film'): 1, ('hard', 'time'): 1, ('...  \n",
       "13  {('film', 'star'): 1, ('refer', 'extern'): 1, ...  \n",
       "14  {('end', 'definit'): 1, ('festiv', 'releas'): ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the data:\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select title, year, imdb reviews, and wikipedia content columns:\n",
    "movie_data = data[[\"title\", \"year\", \"reviews\", \"content\"]]\n",
    "\n",
    "# Create a new type variable which says whether a review or content, \n",
    "# and consider each review and content its own document.\n",
    "movie_data = movie_data.melt(id_vars = [\"title\", \"year\"], value_vars=[\"reviews\", \"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dead Awake</td>\n",
       "      <td>2016</td>\n",
       "      <td>reviews</td>\n",
       "      <td>movi new havent seen name 3 4 last yeari famil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Good American</td>\n",
       "      <td>2015</td>\n",
       "      <td>reviews</td>\n",
       "      <td>documentari show situat idea know bit heard re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hard Tide</td>\n",
       "      <td>2015</td>\n",
       "      <td>reviews</td>\n",
       "      <td>watch rot last night tempt dont bother script ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carrie Pilby</td>\n",
       "      <td>2016</td>\n",
       "      <td>reviews</td>\n",
       "      <td>excit see film toronto filmfest last week enjo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Dark Song</td>\n",
       "      <td>2016</td>\n",
       "      <td>reviews</td>\n",
       "      <td>writer felt job review mere whine prattl happe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title  year variable  \\\n",
       "0       Dead Awake  2016  reviews   \n",
       "1  A Good American  2015  reviews   \n",
       "2        Hard Tide  2015  reviews   \n",
       "3     Carrie Pilby  2016  reviews   \n",
       "4      A Dark Song  2016  reviews   \n",
       "\n",
       "                                               value  \n",
       "0  movi new havent seen name 3 4 last yeari famil...  \n",
       "1  documentari show situat idea know bit heard re...  \n",
       "2  watch rot last night tempt dont bother script ...  \n",
       "3  excit see film toronto filmfest last week enjo...  \n",
       "4  writer felt job review mere whine prattl happe...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the new data:\n",
    "movie_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the documents as a list of strings:\n",
    "docs = movie_data[[\"value\"]].astype(str)['value'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove common words and tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "numbers = \"\"\n",
    "for i in range(0,999):\n",
    "    numbers += str(i) + \" \"\n",
    "letters = set('a b c d e f g h i j k l m n o p q r s t u v w x y z'.split())\n",
    "words_to_remove = stop_words.union(numbers).union(letters)\n",
    "texts = [[word for word in document.lower().split() if word not in words_to_remove]\n",
    "         for document in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove words that appear only once\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1        \n",
    "texts = [[token for token in text if frequency[token] > 9] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary indexing the unique terms:\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "# store the dictionary, for future reference\n",
    "dictionary.save('wiki.dict') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a sparsely formatted corpus:\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Store to disk, for later use:\n",
    "corpora.MmCorpus.serialize('wiki.mm', corpus)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify a number of topics:\n",
    "K = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the LDA model (100 topics, 10 passes takes about 1/2 hour, 3 topics 3 passes takes 5 min):\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=K, id2word = dictionary, passes=20, alpha=.1/K, eta=.1/K)\n",
    "\n",
    "# Save the model object for visualization:\n",
    "ldamodel.save('wiki.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collect phi matrix of topic word proportions, theta matrix of document topic proportions, f_v of word frequencies\n",
    "# p_v of term probabilities, V_n of unique terms in each document, W_v of document lengths, f_k of number of words \n",
    "# used in each topic, and p_k probabilities of each topic occurring, and bayes probabilities of a topic given a word,\n",
    "# and a vocab list of terms:\n",
    "phi_kv = np.zeros((K, len(dictionary)))\n",
    "theta_nk = np.zeros((len(corpus), K))\n",
    "for k in range(0,K):\n",
    "    phi_kv[k,:] = [word_prob[1] for word_prob in lda_mult.get_topic_terms(k, len(dictionary))]\n",
    "for n in range(0,len(corpus)):\n",
    "    theta_nk[n,:] = np.array([topic_probs_double[1] for topic_probs_double in ldamodel.get_document_topics(corpus[n], minimum_probability=0)])\n",
    "counts = Counter()\n",
    "for text in texts:\n",
    "    for word in text:\n",
    "        counts[word] += 1\n",
    "f_v = np.array([counts[dictionary[word_ind]] for word_ind in range(len(dictionary))])\n",
    "p_v = f_v/sum(f_v)\n",
    "V_n = np.array([len(doc) for doc in corpus])\n",
    "W_n = np.array([sum(word[1] for word in doc) for doc in corpus]) \n",
    "f_k = [sum(theta_nk[:,k]*W_n) for k in range(K)]\n",
    "p_k = f_k/sum(f_k)\n",
    "bayes_kv = np.zeros((K, len(dictionary)))\n",
    "for k in range(K):\n",
    "    bayes_kv[k,:] = phi_kv[k,:]*p_k[k]/p_v\n",
    "vocab = [dictionary[i] for i in range(len(dictionary))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {'topic_term_dists': phi_kv, \n",
    "            'doc_topic_dists': theta_nk,\n",
    "            'doc_lengths': W_n,\n",
    "            'vocab': vocab,\n",
    "            'term_frequency': f_v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_vis_data = pyLDAvis.prepare(**data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.display(movies_vis_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify number of top words:\n",
    "num_top_words = 10\n",
    "\n",
    "# Show top words from each topic:\n",
    "for k in range(K):\n",
    "    print(\"topic \" + str(k) + \":\")\n",
    "    topic_top_words = ldamodel.show_topic(k)\n",
    "    for top_word in topic_top_words:\n",
    "        print((top_word[0],format(top_word[1],\".2f\")))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain topic distribution for each movie review and every movie content:\n",
    "topic_probs = []\n",
    "for document in corpus:\n",
    "    topic_probs.append(np.array([topic_probs_double[1] for topic_probs_double in ldamodel.get_document_topics(document, minimum_probability=0)]))\n",
    "topic_probs_array = np.asarray(topic_probs)\n",
    "topic_probs_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pairwise negative hellinger distance matrix for documents:\n",
    "#document_similarities = calc_pairwise_sims_matrix(topic_probs_array, \"hellinger\")\n",
    "\n",
    "# Compute pairwise cosine similarity matrix for documents:\n",
    "document_similarities = calc_pairwise_sims_matrix(topic_probs_array, \"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the 10 documents most similar to a specified movie:\n",
    "movie_title = \"The Search for Santa Paws\"\n",
    "titanic_index = movie_data.loc[movie_data['title'] == movie_title].index[0:2][0]\n",
    "titanic_similarities = document_similarities[titanic_index, :]\n",
    "closest_movies = sorted(range(len(titanic_similarities)), key=lambda k: -titanic_similarities[k])\n",
    "movie_data['title'].loc[closest_movies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute matrix of topic distribution similarities:\n",
    "#topic_similarity_matrix = np.zeros((len(corpus), len(corpus)))\n",
    "#for i in range(5):\n",
    "#    for j in range(5):\n",
    "#        topic_similarity_matrix[i,j] = gensim.matutils.cossim([topic_probs_double[1] for topic_probs_double in ldamodel.get_document_topics(corpus[i], minimum_probability=0)], [topic_probs_double[1] for topic_probs_double in ldamodel.get_document_topics(corpus[j], minimum_probability=0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain topic distribution for each movie review and every movie content:\n",
    "#topic_probs = []\n",
    "#for document in corpus:\n",
    "#    topic_probs.append(np.array([topic_probs_double[1] for topic_probs_double in lda_mult.get_document_topics(document, minimum_probability=0)]))\n",
    "#topic_probs_array = np.asarray(topic_probs)\n",
    "#topic_probs_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TO DO: FIND TOP WORDS BY BAYES RULE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute tf-idf for each document:\n",
    "tf_idf = gensim.models.TfidfModel(corpus)\n",
    "\n",
    "# Compute similarity for each document pair:\n",
    "document_similarities = gensim.similarities.Similarity('doc_sims',tf_idf[corpus],\n",
    "                                      num_features=len(dictionary))\n",
    "\n",
    "# Find the similarity of movies to a query movie:\n",
    "query_doc = [w.lower() for w in texts[157]]\n",
    "print(query_doc)\n",
    "query_doc_bow = dictionary.doc2bow(query_doc)\n",
    "print(query_doc_bow)\n",
    "query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "print(query_doc_tf_idf)\n",
    "sims[query_doc_tf_idf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit the LDA model with multi core (3 topics 3 iterations 3 passes, 4 min):\n",
    "#lda_mult = LdaMulticore(corpus, num_topics=K, id2word=dictionary, iterations = 3, passes = 3, alpha=.1/K, eta=.1/K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the corpus in Blei's LDA-C format:\n",
    "#corpora.BleiCorpus.serialize('wiki.lda-c', corpus)\n",
    "\n",
    "# Read in the corpus in Blei's LDA-C format:\n",
    "#corpus_ldac = corpora.BleiCorpus('wiki.lda-c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# format time slices:\n",
    "#time_slices = {i: 0 for i in range(1939,2018)}\n",
    "#for year in movie_data['year']:\n",
    "#    time_slices[year] += 1\n",
    "#time_slices = [val for val in time_slices.values()]\n",
    "#time_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run dynamic lda on the wikipedia and imdb corpus:\n",
    "#model = DtmModel('dtm-win64.exe', corpus_ldac, time_slices, num_topics=3, id2word=dictionary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
